{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsgHXrZjF1U_"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 0. Environment Setup\n",
        "# =============================================================================\n",
        "# !pip install transformers[torch] datasets accelerate sentencepiece scikit-learn matplotlib bitsandbytes -U\n",
        "\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import gc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForCausalLM,\n",
        "    get_scheduler,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "# =============================================================================\n",
        "# 1. Hardware & Path Configuration\n",
        "# =============================================================================\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"Ensure experimental reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Automated BF16 detection for A100 optimization\n",
        "if torch.cuda.is_available() and torch.cuda.is_bf16_supported():\n",
        "    print(\"ðŸš€ A100 detected: Enabling BF16 Mixed Precision for training.\")\n",
        "    dtype_config = torch.bfloat16\n",
        "else:\n",
        "    print(\"âš ï¸ BF16 not supported: Falling back to FP32.\")\n",
        "    dtype_config = torch.float32\n",
        "\n",
        "CONFIG = {\n",
        "    \"deberta_model\": \"microsoft/deberta-v3-large\",\n",
        "    \"llm_model\": \"Qwen/Qwen2.5-14B-Instruct\",\n",
        "\n",
        "    # Dataset Paths\n",
        "    \"train_files\": [\n",
        "        os.path.join(BASE_PATH, \"dev_track_a.jsonl\"),\n",
        "        os.path.join(BASE_PATH, \"synthetic_data_for_contrastive_learning.jsonl\")\n",
        "    ],\n",
        "    \"test_file\":  os.path.join(BASE_PATH, \"test_track_a.jsonl\"),\n",
        "\n",
        "    # Output Paths\n",
        "    \"output_file\": os.path.join(BASE_PATH, \"track_a_final_submission.jsonl\"),\n",
        "    \"best_deberta_path\": os.path.join(BASE_PATH, \"best_deberta_fixed.pt\"),\n",
        "    \"error_log_path\": os.path.join(BASE_PATH, \"error_analysis.json\"),\n",
        "\n",
        "    # Training Hyperparameters\n",
        "    \"max_len\": 512,\n",
        "    \"batch_size\": 8,\n",
        "    \"accum_steps\": 4, # Effective batch size = 32\n",
        "    \"epochs\": 4,\n",
        "    \"lr\": 1e-5,\n",
        "    \"device\": \"cuda\"\n",
        "}\n",
        "\n",
        "# =============================================================================\n",
        "# 2. Data Engineering\n",
        "# =============================================================================\n",
        "def normalize_data(item):\n",
        "    \"\"\"Harmonize different data formats into a unified ranking structure.\"\"\"\n",
        "    def is_valid(s): return isinstance(s, str) and len(s.strip()) > 0\n",
        "\n",
        "    # Format A: Standard Ranking\n",
        "    if is_valid(item.get('anchor_text')) and is_valid(item.get('text_a')) and is_valid(item.get('text_b')):\n",
        "        return item\n",
        "\n",
        "    # Format B: Triplet Story (Contrastive Learning)\n",
        "    if is_valid(item.get('anchor_story')) and is_valid(item.get('similar_story')) and is_valid(item.get('dissimilar_story"
      ]
    }
  ]
}